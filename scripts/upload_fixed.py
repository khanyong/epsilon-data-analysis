import pandas as pd
import os
import json
from supabase import create_client, Client
from dotenv import load_dotenv
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

def get_table_column_mapping():
    """ê° í…Œì´ë¸”ë³„ ì •í™•í•œ ì»¬ëŸ¼ ë§¤í•‘"""
    return {
        "euro_pricing_country_routes": {
            "source_columns": ["country1", "country2", "subregion1", "subregion2", "region1", "region2", 
                             "2017", "2018", "2019", "2020", "2021", "2022", "2023", "2024", 
                             "2025", "2026", "2027", "2028", "2029", "2030", "2023-30"],
            "target_columns": ["country1", "country2", "subregion1", "subregion2", "region1", "region2",
                             "year_2017", "year_2018", "year_2019", "year_2020", "year_2021", "year_2022", 
                             "year_2023", "year_2024", "year_2025", "year_2026", "year_2027", "year_2028", 
                             "year_2029", "year_2030", "cagr_2023_30"]
        },
        "euro_pricing_wholesale_prices": {
            "source_columns": ["wholesale_prices", "2017", "2018", "2019", "2020", "2021", "2022", "2023", 
                             "2024", "2025", "2026", "2027", "2028", "2029", "2030", "cagr_2023_30"],
            "target_columns": ["route_name", "year_2017", "year_2018", "year_2019", "year_2020", 
                             "year_2021", "year_2022", "year_2023", "year_2024", "year_2025", 
                             "year_2026", "year_2027", "year_2028", "year_2029", "year_2030", "cagr_2023_30"]
        },
        "euro_pricing_trans_atlantic": {
            "source_columns": ["trans_atlantic_deployments_prices_and_revenues", "2017", "2018", "2019", "2020", "2021", "2022", "2023", 
                             "2024", "2025", "2026", "2027", "2028", "2029", "2030", "cagr_2023_30"],
            "target_columns": ["metric_name", "year_2017", "year_2018", "year_2019", "year_2020", 
                             "year_2021", "year_2022", "year_2023", "year_2024", "year_2025", 
                             "year_2026", "year_2027", "year_2028", "year_2029", "year_2030", "cagr_2023_30"]
        },
        "euro_pricing_trans_pacific": {
            "source_columns": ["trans_pacific_deployments_prices_and_revenues", "2017", "2018", "2019", "2020", "2021", "2022", "2023", 
                             "2024", "2025", "2026", "2027", "2028", "2029", "2030", "cagr_2023_30"],
            "target_columns": ["metric_name", "year_2017", "year_2018", "year_2019", "year_2020", 
                             "year_2021", "year_2022", "year_2023", "year_2024", "year_2025", 
                             "year_2026", "year_2027", "year_2028", "year_2029", "year_2030", "cagr_2023_30"]
        },
        "euro_pricing_lease_iru_calculator": {
            "source_columns": ["parameter", "value", "unit", "note"],
            "target_columns": ["parameter", "value", "unit", "note"]
        }
    }

def upload_country_routes(supabase, excel_file_path):
    """Country Routes ì‹œíŠ¸ ì—…ë¡œë“œ"""
    logger.info("ğŸ”„ Country Routes ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘...")
    
    try:
        df = pd.read_excel(excel_file_path, sheet_name='Country Routes')
        
        # í—¤ë” í–‰ ì°¾ê¸°
        header_row = None
        for idx, row in df.iterrows():
            if any(str(cell).isdigit() and len(str(cell)) == 4 for cell in row if pd.notna(cell)):
                header_row = idx
                break
        
        if header_row is not None:
            df = df.iloc[header_row:].reset_index(drop=True)
            df.columns = df.iloc[0]
            df = df.iloc[1:].reset_index(drop=True)
            df = df[df.iloc[:, 0].notna() & (df.iloc[:, 0] != '')]
        
        # ì»¬ëŸ¼ ë§¤í•‘
        column_map = {}
        expected_cols = ["Country1", "Country2", "Subregion1", "Subregion2", "Region1", "Region2"]
        
        for i, col in enumerate(df.columns[:6]):
            if i < len(expected_cols):
                column_map[col] = expected_cols[i]
        
        # ë…„ë„ ì»¬ëŸ¼ ì²˜ë¦¬
        year_columns = []
        for col in df.columns[6:]:
            if pd.notna(col) and str(col).replace('.0', '').isdigit():
                year = str(col).replace('.0', '')
                column_map[col] = year
                year_columns.append(year)
        
        # CAGR ì»¬ëŸ¼ (ë§ˆì§€ë§‰ ì»¬ëŸ¼)
        if len(df.columns) > 20:
            column_map[df.columns[-1]] = "CAGR"
        
        # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
        df_renamed = df.rename(columns=column_map)
        
        # Supabase ì—…ë¡œë“œìš© ë°ì´í„° ì¤€ë¹„
        records = []
        for _, row in df_renamed.iterrows():
            record = {
                "country1": str(row.get("Country1", "")),
                "country2": str(row.get("Country2", "")),
                "subregion1": str(row.get("Subregion1", "")),
                "subregion2": str(row.get("Subregion2", "")),
                "region1": str(row.get("Region1", "")),
                "region2": str(row.get("Region2", ""))
            }
            
            # ë…„ë„ ë°ì´í„° ì¶”ê°€
            for year in ["2017", "2018", "2019", "2020", "2021", "2022", "2023", "2024", "2025", "2026", "2027", "2028", "2029", "2030"]:
                if year in row.index and pd.notna(row[year]):
                    try:
                        record[f"year_{year}"] = float(row[year]) if str(row[year]).replace('.', '').replace('-', '').isdigit() else None
                    except:
                        record[f"year_{year}"] = None
                else:
                    record[f"year_{year}"] = None
            
            # CAGR ì¶”ê°€
            if "CAGR" in row.index:
                record["cagr_2023_30"] = str(row["CAGR"]) if pd.notna(row["CAGR"]) else None
            else:
                record["cagr_2023_30"] = None
            
            records.append(record)
        
        logger.info(f"  ğŸ“¤ {len(records)}ê°œ ë ˆì½”ë“œë¥¼ ì—…ë¡œë“œ ì¤‘...")
        
        # ë°°ì¹˜ ì—…ë¡œë“œ (1000ê°œì”©)
        batch_size = 1000
        total_uploaded = 0
        
        for i in range(0, len(records), batch_size):
            batch = records[i:i+batch_size]
            try:
                result = supabase.table("euro_pricing_country_routes").insert(batch).execute()
                total_uploaded += len(batch)
                logger.info(f"  âœ… {len(batch)}ê°œ ë ˆì½”ë“œ ì—…ë¡œë“œ ì™„ë£Œ (ì´ {total_uploaded}/{len(records)})")
            except Exception as e:
                logger.error(f"  âŒ ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        logger.info(f"  ğŸ‰ Country Routes ì™„ë£Œ: ì´ {total_uploaded}ê°œ ë ˆì½”ë“œ ì—…ë¡œë“œ")
        
    except Exception as e:
        logger.error(f"âŒ Country Routes ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

def upload_lease_calculator(supabase, excel_file_path):
    """Lease-IRU Calculator ì‹œíŠ¸ ì—…ë¡œë“œ"""
    logger.info("ğŸ”„ Lease-IRU Calculator ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘...")
    
    try:
        df = pd.read_excel(excel_file_path, sheet_name='Lease-IRU Calculator')
        
        # ë°ì´í„° ì •ë¦¬
        df = df.dropna(how='all')
        
        records = []
        for _, row in df.iterrows():
            if pd.notna(row.iloc[0]) and str(row.iloc[0]).strip() != '':
                record = {
                    "parameter": str(row.iloc[0]) if pd.notna(row.iloc[0]) else "",
                    "value": str(row.iloc[1]) if len(row) > 1 and pd.notna(row.iloc[1]) else "",
                    "unit": str(row.iloc[2]) if len(row) > 2 and pd.notna(row.iloc[2]) else "",
                    "note": str(row.iloc[3]) if len(row) > 3 and pd.notna(row.iloc[3]) else ""
                }
                records.append(record)
        
        if records:
            logger.info(f"  ğŸ“¤ {len(records)}ê°œ ë ˆì½”ë“œë¥¼ ì—…ë¡œë“œ ì¤‘...")
            result = supabase.table("euro_pricing_lease_iru_calculator").insert(records).execute()
            logger.info(f"  âœ… Lease Calculator ì™„ë£Œ: {len(records)}ê°œ ë ˆì½”ë“œ ì—…ë¡œë“œ")
        else:
            logger.warning("  âš ï¸ ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        logger.error(f"âŒ Lease Calculator ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # Supabase ì„¤ì •
    supabase_url = os.getenv('VITE_SUPABASE_URL')
    supabase_key = os.getenv('VITE_SUPABASE_KEY')
    
    if not supabase_url or not supabase_key:
        logger.error("âŒ Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    supabase: Client = create_client(supabase_url, supabase_key)
    excel_file_path = "data/euro_pricing_table/q2_all_data.xlsx"
    
    if not os.path.exists(excel_file_path):
        logger.error(f"âŒ Excel íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_file_path}")
        return
    
    logger.info("=== ìˆ˜ì •ëœ Euro Pricing ë°ì´í„° ì—…ë¡œë“œ ===")
    
    # ì£¼ìš” ì‹œíŠ¸ë“¤ë§Œ ì—…ë¡œë“œ
    upload_country_routes(supabase, excel_file_path)
    upload_lease_calculator(supabase, excel_file_path)
    
    logger.info("âœ… ì—…ë¡œë“œ ì™„ë£Œ!")

if __name__ == "__main__":
    main()