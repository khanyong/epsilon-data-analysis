import pandas as pd
import os
from supabase import create_client, Client
from dotenv import load_dotenv
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

def clear_and_recreate_tables(supabase):
    """ê¸°ì¡´ í…Œì´ë¸” ë°ì´í„° ì‚­ì œ"""
    tables_to_clear = [
        "euro_pricing_home",
        "euro_pricing_charts", 
        "euro_pricing_regions",
        "euro_pricing_countries",
        "euro_pricing_route_summary"
    ]
    
    for table in tables_to_clear:
        try:
            logger.info(f"ğŸ—‘ï¸ {table} í…Œì´ë¸” ë°ì´í„° ì‚­ì œ ì¤‘...")
            result = supabase.table(table).delete().neq('id', 0).execute()
            logger.info(f"âœ… {table} ì‚­ì œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ {table} ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

def upload_regions_properly(supabase, excel_file_path):
    """Regions ì‹œíŠ¸ë¥¼ ì œëŒ€ë¡œ ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì—…ë¡œë“œ"""
    logger.info("ğŸ”„ Regions ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘...")
    
    try:
        df = pd.read_excel(excel_file_path, sheet_name='Regions')
        
        # ì‹¤ì œ ë°ì´í„°ê°€ ì‹œì‘í•˜ëŠ” í–‰ ì°¾ê¸° (ì§€ì—­ëª…ì´ ìˆëŠ” í–‰)
        data_start = None
        for idx, row in df.iterrows():
            if pd.notna(row.iloc[0]) and str(row.iloc[0]).strip() not in ['', 'Used International Bandwidth by Region', '[HOME]']:
                # ì§€ì—­ëª…ì¸ì§€ í™•ì¸
                cell_value = str(row.iloc[0]).strip()
                if any(region in cell_value for region in ['Asia', 'Europe', 'America', 'Africa', 'Middle East', 'Total']):
                    data_start = idx
                    break
        
        if data_start is not None:
            # í—¤ë” ì •ë³´ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •
            df_data = df.iloc[data_start:].reset_index(drop=True)
            
            # ì»¬ëŸ¼ëª… ë§¤í•‘
            column_mapping = {
                df_data.columns[0]: "region_name"
            }
            
            # ë…„ë„ ì»¬ëŸ¼ë“¤ ì°¾ê¸° (Historicalê³¼ Forecasts ì„¹ì…˜)
            year_cols = []
            col_idx = 1
            
            # Historical ë…„ë„ë“¤ (ëŒ€ëµ 2017-2023)
            historical_years = ["2017", "2018", "2019", "2020", "2021", "2022", "2023"]
            for year in historical_years:
                if col_idx < len(df_data.columns):
                    column_mapping[df_data.columns[col_idx]] = f"historical_{year}"
                    col_idx += 1
            
            # Forecasts ë…„ë„ë“¤ (ëŒ€ëµ 2024-2030)
            forecast_years = ["2024", "2025", "2026", "2027", "2028", "2029", "2030"]
            for year in forecast_years:
                if col_idx < len(df_data.columns):
                    column_mapping[df_data.columns[col_idx]] = f"forecast_{year}"
                    col_idx += 1
            
            # ë‚¨ì€ ì»¬ëŸ¼ë“¤ì€ ê¸°íƒ€ ì •ë³´ë¡œ ì²˜ë¦¬
            while col_idx < len(df_data.columns):
                column_mapping[df_data.columns[col_idx]] = f"additional_data_{col_idx}"
                col_idx += 1
            
            # ë°ì´í„° ë³€í™˜
            df_renamed = df_data.rename(columns=column_mapping)
            
            # ë ˆì½”ë“œ ìƒì„±
            records = []
            for _, row in df_renamed.iterrows():
                if pd.notna(row['region_name']) and str(row['region_name']).strip() != '':
                    record = {"region_name": str(row['region_name']).strip()}
                    
                    # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ë“¤ ì¶”ê°€
                    for col in df_renamed.columns[1:]:
                        if col in row.index and pd.notna(row[col]):
                            try:
                                record[col] = float(row[col]) if str(row[col]).replace('.', '').replace('-', '').isdigit() else str(row[col])
                            except:
                                record[col] = str(row[col]) if pd.notna(row[col]) else None
                        else:
                            record[col] = None
                    
                    records.append(record)
            
            if records:
                logger.info(f"  ğŸ“¤ {len(records)}ê°œ ë ˆì½”ë“œë¥¼ ì—…ë¡œë“œ ì¤‘...")
                result = supabase.table("euro_pricing_regions").insert(records).execute()
                logger.info(f"  âœ… Regions ì™„ë£Œ: {len(records)}ê°œ ë ˆì½”ë“œ ì—…ë¡œë“œ")
            else:
                logger.warning("  âš ï¸ ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            logger.warning("  âš ï¸ ë°ì´í„° ì‹œì‘ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        logger.error(f"âŒ Regions ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

def upload_countries_properly(supabase, excel_file_path):
    """Countries ì‹œíŠ¸ë¥¼ ì œëŒ€ë¡œ ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì—…ë¡œë“œ"""
    logger.info("ğŸ”„ Countries ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘...")
    
    try:
        df = pd.read_excel(excel_file_path, sheet_name='Countries')
        
        # ì‹¤ì œ ë°ì´í„°ê°€ ì‹œì‘í•˜ëŠ” í–‰ ì°¾ê¸° (êµ­ê°€ëª…ì´ ìˆëŠ” í–‰)
        data_start = None
        for idx, row in df.iterrows():
            if pd.notna(row.iloc[0]) and str(row.iloc[0]).strip() not in ['', 'Used International Bandwidth by Country', '[HOME]']:
                # êµ­ê°€ëª…ì¸ì§€ í™•ì¸ (ì•ŒíŒŒë²³ìœ¼ë¡œ ì‹œì‘í•˜ê³  ì ì ˆí•œ ê¸¸ì´)
                cell_value = str(row.iloc[0]).strip()
                if len(cell_value) > 2 and cell_value.replace(' ', '').isalpha():
                    data_start = idx
                    break
        
        if data_start is not None:
            # ë°ì´í„° ì²˜ë¦¬ (ì²˜ìŒ 50ê°œ ë ˆì½”ë“œë§Œ - í…Œì´ë¸”ì´ ë„ˆë¬´ í¬ë¯€ë¡œ)
            df_data = df.iloc[data_start:data_start+50].reset_index(drop=True)
            
            records = []
            for _, row in df_data.iterrows():
                if pd.notna(row.iloc[0]) and str(row.iloc[0]).strip() != '':
                    record = {
                        "country_name": str(row.iloc[0]).strip(),
                        "total_bandwidth_historical": str(row.iloc[2]) if len(row) > 2 and pd.notna(row.iloc[2]) else None,
                        "total_bandwidth_forecast": str(row.iloc[8]) if len(row) > 8 and pd.notna(row.iloc[8]) else None,
                        "backbone_providers_historical": str(row.iloc[16]) if len(row) > 16 and pd.notna(row.iloc[16]) else None,
                        "backbone_providers_forecast": str(row.iloc[23]) if len(row) > 23 and pd.notna(row.iloc[23]) else None,
                        "content_providers_historical": str(row.iloc[31]) if len(row) > 31 and pd.notna(row.iloc[31]) else None,
                        "content_providers_forecast": str(row.iloc[38]) if len(row) > 38 and pd.notna(row.iloc[38]) else None
                    }
                    records.append(record)
            
            if records:
                logger.info(f"  ğŸ“¤ {len(records)}ê°œ ë ˆì½”ë“œë¥¼ ì—…ë¡œë“œ ì¤‘...")
                result = supabase.table("euro_pricing_countries").insert(records).execute()
                logger.info(f"  âœ… Countries ì™„ë£Œ: {len(records)}ê°œ ë ˆì½”ë“œ ì—…ë¡œë“œ")
            else:
                logger.warning("  âš ï¸ ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            logger.warning("  âš ï¸ ë°ì´í„° ì‹œì‘ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        logger.error(f"âŒ Countries ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

def upload_route_summary_properly(supabase, excel_file_path):
    """Route Summary ì‹œíŠ¸ë¥¼ ì œëŒ€ë¡œ ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì—…ë¡œë“œ"""
    logger.info("ğŸ”„ Route Summary ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘...")
    
    try:
        df = pd.read_excel(excel_file_path, sheet_name='Route Summary')
        
        # ì‹¤ì œ ë°ì´í„°ê°€ ì‹œì‘í•˜ëŠ” í–‰ ì°¾ê¸°
        data_start = None
        for idx, row in df.iterrows():
            if pd.notna(row.iloc[0]) and str(row.iloc[0]).strip() not in ['', 'Submarine Cable Route Summary', '[HOME]', 'Used Bandwidth (Gbps)']:
                cell_value = str(row.iloc[0]).strip()
                if '-' in cell_value or any(region in cell_value for region in ['Trans-Atlantic', 'Trans-Pacific', 'US-', 'Europe-', 'Intra-']):
                    data_start = idx
                    break
        
        if data_start is not None:
            df_data = df.iloc[data_start:].reset_index(drop=True)
            
            records = []
            for _, row in df_data.iterrows():
                if pd.notna(row.iloc[0]) and str(row.iloc[0]).strip() != '':
                    record = {
                        "route_name": str(row.iloc[0]).strip(),
                        "historical_data": str(row.iloc[5]) if len(row) > 5 and pd.notna(row.iloc[5]) else None,
                        "forecast_data": str(row.iloc[8]) if len(row) > 8 and pd.notna(row.iloc[8]) else None,
                        "change_data": str(row.iloc[20]) if len(row) > 20 and pd.notna(row.iloc[20]) else None
                    }
                    records.append(record)
            
            if records:
                logger.info(f"  ğŸ“¤ {len(records)}ê°œ ë ˆì½”ë“œë¥¼ ì—…ë¡œë“œ ì¤‘...")
                result = supabase.table("euro_pricing_route_summary").insert(records).execute()
                logger.info(f"  âœ… Route Summary ì™„ë£Œ: {len(records)}ê°œ ë ˆì½”ë“œ ì—…ë¡œë“œ")
            else:
                logger.warning("  âš ï¸ ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            logger.warning("  âš ï¸ ë°ì´í„° ì‹œì‘ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        logger.error(f"âŒ Route Summary ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # Supabase ì„¤ì •
    supabase_url = os.getenv('VITE_SUPABASE_URL')
    supabase_key = os.getenv('VITE_SUPABASE_KEY')
    
    if not supabase_url or not supabase_key:
        logger.error("âŒ Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    supabase: Client = create_client(supabase_url, supabase_key)
    excel_file_path = "data/euro_pricing_table/q2_all_data.xlsx"
    
    if not os.path.exists(excel_file_path):
        logger.error(f"âŒ Excel íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_file_path}")
        return
    
    logger.info("=== ê¸°ì¡´ í…Œì´ë¸” ì •ë¦¬ ë° ì¬ì—…ë¡œë“œ ===")
    
    # 1. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    clear_and_recreate_tables(supabase)
    
    # 2. ì œëŒ€ë¡œ ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì¬ì—…ë¡œë“œ
    upload_regions_properly(supabase, excel_file_path)
    upload_countries_properly(supabase, excel_file_path)
    upload_route_summary_properly(supabase, excel_file_path)
    
    logger.info("âœ… ëª¨ë“  í…Œì´ë¸”ì´ ì œëŒ€ë¡œ ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()