import pandas as pd
import os
import json
from supabase import create_client, Client
from dotenv import load_dotenv
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

def upload_euro_pricing_data():
    """Euro Pricing ë°ì´í„°ë¥¼ Supabaseì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    
    # Supabase ì„¤ì •
    supabase_url = os.getenv('VITE_SUPABASE_URL')
    supabase_key = os.getenv('VITE_SUPABASE_KEY')
    
    if not supabase_url or not supabase_key:
        logger.error("âŒ Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        logger.info("ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”:")
        logger.info("- VITE_SUPABASE_URL")
        logger.info("- VITE_SUPABASE_KEY")
        return
    
    # Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    supabase: Client = create_client(supabase_url, supabase_key)
    
    # Excel íŒŒì¼ ê²½ë¡œ
    excel_file_path = "data/euro_pricing_table/q2_all_data.xlsx"
    
    if not os.path.exists(excel_file_path):
        logger.error(f"âŒ Excel íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_file_path}")
        return
    
    logger.info("=== Euro Pricing ë°ì´í„° Supabase ì—…ë¡œë“œ ===")
    
    try:
        # Excel íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ ì½ê¸°
        excel_file = pd.ExcelFile(excel_file_path)
        sheet_names = excel_file.sheet_names
        
        logger.info(f"ðŸ“Š ë°œê²¬ëœ ì‹œíŠ¸: {sheet_names}")
        
        for sheet_name in sheet_names:
            logger.info(f"\nðŸ”„ ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì¤‘...")
            
            try:
                # ì‹œíŠ¸ ë°ì´í„° ì½ê¸°
                df = pd.read_excel(excel_file_path, sheet_name=sheet_name)
                
                logger.info(f"  - ë°ì´í„° í˜•íƒœ: {df.shape}")
                logger.info(f"  - ì»¬ëŸ¼: {list(df.columns)}")
                
                # ë°ì´í„° ì „ì²˜ë¦¬
                df_cleaned = preprocess_dataframe(df, sheet_name)
                
                if df_cleaned.empty:
                    logger.warning(f"  âš ï¸ ì‹œíŠ¸ '{sheet_name}'ì— ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # Supabaseì— ì—…ë¡œë“œ
                table_name = f"euro_pricing_{sheet_name.lower().replace(' ', '_').replace('-', '_')}"
                upload_to_supabase(supabase, df_cleaned, table_name, sheet_name)
                
            except Exception as e:
                logger.error(f"  âŒ ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        logger.info("\nâœ… ëª¨ë“  ì‹œíŠ¸ ì²˜ë¦¬ ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"âŒ Excel íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")

def preprocess_dataframe(df, sheet_name):
    """ë°ì´í„°í”„ë ˆìž„ ì „ì²˜ë¦¬"""
    
    # ë¹ˆ í–‰/ì—´ ì œê±°
    df = df.dropna(how='all').dropna(axis=1, how='all')
    
    if df.empty:
        return df
    
    # ì‹œíŠ¸ë³„ íŠ¹ë³„ ì²˜ë¦¬
    if 'Country Routes' in sheet_name:
        # Country Routes ì‹œíŠ¸ëŠ” ì‹¤ì œ ë°ì´í„°ê°€ ìžˆëŠ” ì‹œíŠ¸
        # í—¤ë” í–‰ ì°¾ê¸° (ìˆ«ìž ì—°ë„ê°€ ìžˆëŠ” í–‰)
        header_row = None
        for idx, row in df.iterrows():
            if any(str(cell).isdigit() and len(str(cell)) == 4 for cell in row if pd.notna(cell)):
                header_row = idx
                break
        
        if header_row is not None:
            # í—¤ë” í–‰ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì„¤ì •
            df = df.iloc[header_row:].reset_index(drop=True)
            df.columns = df.iloc[0]
            df = df.iloc[1:].reset_index(drop=True)
            
            # ì‹¤ì œ ë°ì´í„°ë§Œ í•„í„°ë§ (êµ­ê°€ëª…ì´ ìžˆëŠ” í–‰)
            df = df[df.iloc[:, 0].notna() & (df.iloc[:, 0] != '')]
    
    elif any(keyword in sheet_name for keyword in ['Trans-Atlantic', 'Trans-Pacific', 'US-Latin America', 'Intra-Asia', 'Europe-']):
        # ì§€ì—­ë³„ ë°°í¬/ê°€ê²©/ìˆ˜ìµ ì‹œíŠ¸
        # í—¤ë” í–‰ ì°¾ê¸°
        header_row = None
        for idx, row in df.iterrows():
            if any(str(cell).isdigit() and len(str(cell)) == 4 for cell in row if pd.notna(cell)):
                header_row = idx
                break
        
        if header_row is not None:
            # í—¤ë” í–‰ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì„¤ì •
            df = df.iloc[header_row:].reset_index(drop=True)
            df.columns = df.iloc[0]
            df = df.iloc[1:].reset_index(drop=True)
            
            # ì‹¤ì œ ë°ì´í„°ë§Œ í•„í„°ë§
            df = df[df.iloc[:, 0].notna() & (df.iloc[:, 0] != '')]
    
    elif 'Wholesale Prices' in sheet_name:
        # ê°€ê²© ë°ì´í„° ì‹œíŠ¸
        # í—¤ë” í–‰ ì°¾ê¸°
        header_row = None
        for idx, row in df.iterrows():
            if any(str(cell).isdigit() and len(str(cell)) == 4 for cell in row if pd.notna(cell)):
                header_row = idx
                break
        
        if header_row is not None:
            df = df.iloc[header_row:].reset_index(drop=True)
            df.columns = df.iloc[0]
            df = df.iloc[1:].reset_index(drop=True)
            
            # ì‹¤ì œ ë°ì´í„°ë§Œ í•„í„°ë§
            df = df[df.iloc[:, 0].notna() & (df.iloc[:, 0] != '')]
    
    elif 'Lease-IRU Calculator' in sheet_name:
        # ê³„ì‚°ê¸° ì‹œíŠ¸ëŠ” ê°„ë‹¨í•œ êµ¬ì¡°
        df = df.dropna(how='all')
        if not df.empty:
            # ì»¬ëŸ¼ ìˆ˜ì— ë§žê²Œ ì¡°ì •
            if len(df.columns) >= 4:
                df.columns = ['parameter', 'value', 'unit', 'note']
            elif len(df.columns) == 3:
                df.columns = ['parameter', 'value', 'unit']
            else:
                df.columns = ['parameter', 'value']
    
    else:
        # ê¸°íƒ€ ì‹œíŠ¸ë“¤ì€ ê¸°ë³¸ ì²˜ë¦¬
        # ì²« ë²ˆì§¸ ìœ íš¨í•œ í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©
        for idx, row in df.iterrows():
            if any(pd.notna(cell) and str(cell).strip() != '' for cell in row):
                df = df.iloc[idx:].reset_index(drop=True)
                df.columns = df.iloc[0]
                df = df.iloc[1:].reset_index(drop=True)
                break
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬ (ê³µë°± ì œê±°, ì†Œë¬¸ìž ë³€í™˜, íŠ¹ìˆ˜ë¬¸ìž ì²˜ë¦¬)
    if not df.empty:
        # ì»¬ëŸ¼ëª…ì„ ë¬¸ìžì—´ë¡œ ë³€í™˜í•˜ê³  ì •ë¦¬
        new_columns = []
        for col in df.columns:
            if pd.isna(col) or col == '':
                new_columns.append(f'unnamed_{len(new_columns)}')
            else:
                clean_col = str(col).strip().lower().replace(' ', '_').replace('-', '_').replace('(', '').replace(')', '').replace('.', '_').replace(':', '_').replace('/', '_').replace('&', 'and')
                new_columns.append(clean_col)
        
        df.columns = new_columns
        
        # ë°ì´í„° íƒ€ìž… ë³€í™˜ ë° JSON í˜¸í™˜ì„± ì²˜ë¦¬
        for col in df.columns:
            try:
                if df[col].dtype == 'object':
                    # ë¬¸ìžì—´ ì»¬ëŸ¼ì—ì„œ NaNì„ ë¹ˆ ë¬¸ìžì—´ë¡œ ë³€í™˜
                    df[col] = df[col].fillna('').astype(str)
                    # 'nan' ë¬¸ìžì—´ë„ ë¹ˆ ë¬¸ìžì—´ë¡œ ë³€í™˜
                    df[col] = df[col].replace(['nan', 'NaN', 'None'], '')
                else:
                    # ìˆ«ìž ì»¬ëŸ¼ ì²˜ë¦¬
                    # ë¨¼ì € ë¬´í•œëŒ€ì™€ ë§¤ìš° í°/ìž‘ì€ ê°’ë“¤ì„ Noneìœ¼ë¡œ ë³€í™˜
                    df[col] = df[col].replace([float('inf'), float('-inf')], None)
                    # ë§¤ìš° í° ê°’ë“¤ë„ ì²˜ë¦¬ (JSON ì•ˆì „ ë²”ìœ„)
                    mask_large = df[col].abs() > 1e308
                    df[col] = df[col].where(~mask_large, None)
                    # NaNì„ Noneìœ¼ë¡œ ë³€í™˜
                    df[col] = df[col].where(pd.notna(df[col]), None)
            except Exception as e:
                logger.warning(f"  âš ï¸ ì»¬ëŸ¼ '{col}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                # ì˜¤ë¥˜ê°€ ìžˆëŠ” ì»¬ëŸ¼ì€ ë¬¸ìžì—´ë¡œ ì²˜ë¦¬
                df[col] = df[col].fillna('').astype(str)
    
    return df

def upload_to_supabase(supabase, df, table_name, sheet_name):
    """Supabaseì— ë°ì´í„° ì—…ë¡œë“œ"""
    
    try:
        # ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        records = df.to_dict('records')
        
        if not records:
            logger.warning(f"  âš ï¸ ì‹œíŠ¸ '{sheet_name}'ì— ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # JSON í˜¸í™˜ì„±ì„ ìœ„í•œ ì¶”ê°€ ì²˜ë¦¬
        cleaned_records = []
        for record in records:
            cleaned_record = {}
            for key, value in record.items():
                # ë¬´í•œëŒ€ ê°’ê³¼ NaN ê°’ ì²˜ë¦¬
                if pd.isna(value) or value is None:
                    cleaned_record[key] = None
                elif isinstance(value, (int, float)) and (value == float('inf') or value == float('-inf')):
                    cleaned_record[key] = None
                else:
                    cleaned_record[key] = value
            cleaned_records.append(cleaned_record)
        
        logger.info(f"  ðŸ“¤ {len(cleaned_records)}ê°œ ë ˆì½”ë“œë¥¼ '{table_name}' í…Œì´ë¸”ì— ì—…ë¡œë“œ ì¤‘...")
        
        # Supabaseì— ë°ì´í„° ì‚½ìž…
        result = supabase.table(table_name).insert(cleaned_records).execute()
        
        if result.data:
            logger.info(f"  âœ… ì‹œíŠ¸ '{sheet_name}' ì—…ë¡œë“œ ì„±ê³µ: {len(result.data)}ê°œ ë ˆì½”ë“œ")
        else:
            logger.warning(f"  âš ï¸ ì‹œíŠ¸ '{sheet_name}' ì—…ë¡œë“œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        logger.error(f"  âŒ ì‹œíŠ¸ '{sheet_name}' ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        # í…Œì´ë¸”ì´ ì¡´ìž¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° í…Œì´ë¸” ìƒì„± ì‹œë„
        if "relation" in str(e).lower() and "does not exist" in str(e).lower():
            logger.info(f"  ðŸ”§ í…Œì´ë¸” '{table_name}' ìƒì„± ì‹œë„...")
            create_table_from_dataframe(supabase, df, table_name, sheet_name)

def create_table_from_dataframe(supabase, df, table_name, sheet_name):
    """ë°ì´í„°í”„ë ˆìž„ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…Œì´ë¸” ìƒì„±"""
    
    try:
        # ì»¬ëŸ¼ íƒ€ìž… ë§¤í•‘
        column_types = {}
        for col in df.columns:
            try:
                if df[col].dtype == 'object':
                    column_types[col] = 'text'
                elif df[col].dtype in ['int64', 'int32']:
                    column_types[col] = 'integer'
                elif df[col].dtype in ['float64', 'float32']:
                    column_types[col] = 'numeric'
                else:
                    column_types[col] = 'text'
            except:
                column_types[col] = 'text'
        
        # SQL í…Œì´ë¸” ìƒì„± ì¿¼ë¦¬ ìƒì„±
        columns_sql = []
        for col, col_type in column_types.items():
            # ì»¬ëŸ¼ëª…ì„ SQL ì•ˆì „í•œ í˜•íƒœë¡œ ë³€í™˜
            safe_col = col.replace(' ', '_').replace('-', '_').lower()
            columns_sql.append(f'"{safe_col}" {col_type}')
        
        create_table_sql = f"""
        CREATE TABLE IF NOT EXISTS {table_name} (
            id SERIAL PRIMARY KEY,
            {', '.join(columns_sql)}
        );
        """
        
        logger.info(f"  ðŸ”§ í…Œì´ë¸” ìƒì„± SQL: {create_table_sql}")
        
        # í…Œì´ë¸” ìƒì„± (Supabase SQL ì‹¤í–‰)
        result = supabase.rpc('exec_sql', {'sql': create_table_sql}).execute()
        
        logger.info(f"  âœ… í…Œì´ë¸” '{table_name}' ìƒì„± ì™„ë£Œ")
        
        # ë‹¤ì‹œ ë°ì´í„° ì—…ë¡œë“œ ì‹œë„
        upload_to_supabase(supabase, df, table_name, sheet_name)
        
    except Exception as e:
        logger.error(f"  âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {str(e)}")

def analyze_excel_structure():
    """Excel íŒŒì¼ êµ¬ì¡° ë¶„ì„"""
    
    excel_file_path = "data/euro_pricing_table/q2_all_data.xlsx"
    
    if not os.path.exists(excel_file_path):
        logger.error(f"âŒ Excel íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_file_path}")
        return
    
    try:
        excel_file = pd.ExcelFile(excel_file_path)
        sheet_names = excel_file.sheet_names
        
        logger.info("=== Excel íŒŒì¼ êµ¬ì¡° ë¶„ì„ ===")
        logger.info(f"ðŸ“Š ì´ ì‹œíŠ¸ ìˆ˜: {len(sheet_names)}")
        
        for i, sheet_name in enumerate(sheet_names, 1):
            logger.info(f"\n{i}. ì‹œíŠ¸: '{sheet_name}'")
            
            try:
                df = pd.read_excel(excel_file_path, sheet_name=sheet_name)
                logger.info(f"   - í–‰ ìˆ˜: {df.shape[0]}")
                logger.info(f"   - ì—´ ìˆ˜: {df.shape[1]}")
                logger.info(f"   - ì»¬ëŸ¼: {list(df.columns)}")
                
                # ë°ì´í„° ìƒ˜í”Œ
                if not df.empty:
                    logger.info(f"   - ì²« 3í–‰ ìƒ˜í”Œ:")
                    for idx, row in df.head(3).iterrows():
                        logger.info(f"     {idx}: {dict(row)}")
                
            except Exception as e:
                logger.error(f"   âŒ ì‹œíŠ¸ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
                
    except Exception as e:
        logger.error(f"âŒ Excel íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "analyze":
        analyze_excel_structure()
    else:
        upload_euro_pricing_data() 